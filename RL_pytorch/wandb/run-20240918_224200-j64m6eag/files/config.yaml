_wandb:
    value:
        cli_version: 0.18.0
        code_path: code/rl_pytorch/PPO_fv.py
        m: []
        python_version: 3.12.5
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 13
                - 16
                - 23
                - 35
                - 55
            "4": 3.12.5
            "5": 0.18.0
            "8":
                - 3
                - 5
            "12": 0.18.0
            "13": windows-amd64
anneal_lr:
    value: true
batch_size:
    value: 8192
capture_video:
    value: false
clip_coef:
    value: 0.2
clip_vloss:
    value: false
cuda:
    value: true
ent_coef:
    value: 0
env_id:
    value: EMB-fv
exp_name:
    value: PPO_fv
gae:
    value: true
gae_lambda:
    value: 0.95
gamma:
    value: 0.99
learning_rate:
    value: 0.001
max_grad_norm:
    value: 0.5
minibatch_size:
    value: 256
norm_adv:
    value: true
num_envs:
    value: 4
num_minibatches:
    value: 32
num_steps:
    value: 2048
save_model:
    value: true
seed:
    value: 1
target_kl:
    value: null
test_model:
    value: true
torch_deterministic:
    value: true
total_timesteps:
    value: 500000
track:
    value: true
train_model:
    value: true
update_epochs:
    value: 10
vf_coef:
    value: 0.5
wandb_entity:
    value: null
wandb_project_name:
    value: emb-ppo
